import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import duckdb as db
import pandas as pd
# pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
# pd.set_option('display.width', 2000)
# pd.set_option('display.float_format', '{:20,.2f}'.format)
# pd.set_option('display.max_colwidth', None)
## Python and SQL - Workflow Analysis

df_StpFcEntries = pd.read_excel('Tech_Datasets2024\StpFcEntries.xlsx')
df_contractPaths = pd.read_excel('Tech_Datasets2024\contractPaths.xlsx')
df_WorkflowTaskInfo = pd.read_excel('Tech_Datasets2024\WorkflowTaskInfo.xlsx')
df_WorkflowTaskInfo.head()
df_contractPaths.head()
# print(df_StpFcEntries.columns)
df_StpFcEntries.head()
### Q2

#### Summarize the data by Family, Group and Type and output the number of contracts (not entries) that were processed by the contract workflow. 
Print the relevant columns:
df1 = df_StpFcEntries[['status_taken', 'fc_id', 'fc_cfamily', 'fc_cgroup', 'fc_ctype']]
df1
Find the entries that have been processed:
df1[df1['status_taken'].str.contains('Y')]
Finding Unique Values in a Pandas Dataframe
To find unique values in a Pandas dataframe, we can use the unique() function. This function returns an array of unique values in the dataframe. However, this function only returns unique values within a particular column or row. 
unique_contracts = df1['fc_id'].unique()

print(unique_contracts)
print("Number of contracts processed by the contract workflow = ", len(unique_contracts))

### Q3

#### Output the following statistics per task:
Q3a) Wait-time Average
Q3a.1) First make a dataframe with the needed data:
df2 = df_StpFcEntries[['status_taken', 'wait_time', 'xmlflow_status']]
df2 = df2[df2['status_taken'].str.contains('Y')]
df2 = df2[['xmlflow_status', 'wait_time']]
df2

Q3a.2) Combine/Add the wait times of entries under the same task.
# Add the wait times of the entries under the same task

# To calculate the average we need to know the number of entries per task.
# To do this create an extra column of 1s. This is done so that when the row with 
# the same task are added together, we can see how many entries there were per task.

# Using DataFrame.insert() to add a column
df2.insert(2, "Ones", np.ones(df2.shape[0]), True)
print(df2.head())

df_waitTimePerTask = df2.groupby('xmlflow_status').sum()
df_waitTimePerTask
Q3a.3) Calculate the Average wait time *per task*
df_AverageWaitTimePerTask = df_waitTimePerTask['wait_time']/df_waitTimePerTask['Ones']
df_AverageWaitTimePerTask = df_AverageWaitTimePerTask.reset_index()
df_AverageWaitTimePerTask = df_AverageWaitTimePerTask.rename(columns={0: 'Avg_Wait_Time'})
df_AverageWaitTimePerTask
plot histogram to view outliers
sns.histplot(x = 'Avg_Wait_Time', data=df_AverageWaitTimePerTask, bins=50)
plt.show()
Q3b) Max Wait time *per task*
df_MaxWaitTimePerTask = df2.groupby('xmlflow_status').max()

df_MaxWaitTimePerTask = df_MaxWaitTimePerTask['wait_time']
df_MaxWaitTimePerTask = df_MaxWaitTimePerTask.reset_index()
df_MaxWaitTimePerTask = df_MaxWaitTimePerTask.rename(columns={'wait_time': 'Max_wait_time'})

df_MaxWaitTimePerTask


Q3c) Average Processing Time *per task*
Q3c.1) First make a dataframe with the needed data:
df_processingTimes = df_StpFcEntries[['status_taken', 'proc_time', 'xmlflow_status']]
df_processingTimes = df_processingTimes[df_processingTimes['status_taken'].str.contains('Y')]
df_processingTimes = df_processingTimes[['xmlflow_status', 'proc_time']]
df_processingTimes
Q3c.2) Combine/Add the Processing times of entries under the same task.
# Add the processing times of the entries under the same task

# To calculate the average we need to know the number of entries per task.
# To do this create an extra column of 1s. This is done so that when rows with 
# the same task number are added together, the ones will be added together and we can see how many entries there were per task.

# Using DataFrame.insert() to add a column
df_processingTimes.insert(2, "Ones", np.ones(df_processingTimes.shape[0]), True)
print(df_processingTimes.head())

df_ProcTimePerTask = df_processingTimes.groupby('xmlflow_status').sum()
df_ProcTimePerTask = df_ProcTimePerTask.reset_index()
df_ProcTimePerTask
Q3c.3) Calculate the Average proc time *per task*
df_AverageProcTimePerTask = df_ProcTimePerTask
df_AverageProcTimePerTask['avg_proc_time'] = df_AverageProcTimePerTask['proc_time']/df_AverageProcTimePerTask['Ones']
df_AverageProcTimePerTask
Q3d) Processing Time Max
df_MaxProcTimePerTask = df_ProcTimePerTask[['xmlflow_status', 'proc_time']]
df_MaxProcTimePerTask = df_MaxProcTimePerTask.groupby('xmlflow_status').max()
df_MaxProcTimePerTask = df_MaxProcTimePerTask.rename(columns={'proc_time': 'max_proc_time'})
df_MaxProcTimePerTask = df_MaxProcTimePerTask.reset_index()

df_MaxProcTimePerTask
Q3e) Throughput (per second)
The Throughput(per second) per task was calculated by 1/the average processing time per task 

Frequency = 1/Period

Throughput = 1/Average proc time per task

df_ThroughputPerTask = 1/(df_AverageProcTimePerTask/1000)
df_ThroughputPerTask
Q3f) Throughput (per minute)
df_ThroughputPerTask_PerMinute = df_ThroughputPerTask*60
df_ThroughputPerTask_PerMinute

Q3g) Latency (per second)
Q3g.1) First make a dataframe with the needed data:
df_Throughput = df_StpFcEntries[['status_taken', 'xmlflow_status', 'wait_time', 'proc_time']]
df_Throughput = df_Throughput[df_Throughput['status_taken'].str.contains('Y')]
df_Throughput = df_Throughput[['xmlflow_status', 'wait_time', 'proc_time']]
df_Throughput
Q3g.2) Combine/Add the Processing and Wait times of entries under the same task.
df_ProcAndWaitTimePerTask = df_Throughput.groupby('xmlflow_status').sum()
df_ProcAndWaitTimePerTask
Q3g.3) Latency (per second)
df_LatencyPerTask = df_ProcAndWaitTimePerTask['wait_time'] + df_ProcAndWaitTimePerTask['proc_time']
df_LatencyPerTask = df_LatencyPerTask.reset_index()
df_LatencyPerTask = df_LatencyPerTask.rename(columns = {0:'latency'})

df_LatencyPerTask['xmlflow_status'] = df_LatencyPerTask['xmlflow_status'].astype(str)
df_LatencyPerTask
##### Q4

Graphically show how many entries are waiting to be processed by each task in a bar chart. 


df3 = df_StpFcEntries[['xmlflow_status', 'status_taken']]
df3 = df3[df3['status_taken'].str.contains('N')]

df3.insert(2, "Ones", np.ones(df3.shape[0]), True)

print(df3)


df3 = df3.groupby('xmlflow_status').sum()
df3 = df3.drop('status_taken', axis=1)
df3 = df3.reset_index()

df3
df3['xmlflow_status'] = df3['xmlflow_status'].astype(str)


# Plot entries waiting to be processed
sns.barplot(x='Ones', y='xmlflow_status', data=df3, color="b")
##### Q5

Graphically display the top five tasks in terms of processing time in a line graph for the last week. 


df4 = df_MaxProcTimePerTask
df4 = df4.sort_values('max_proc_time')

df4 = df4.tail(5)

df4

df4['xmlflow_status'] = df4['xmlflow_status'].astype(str)

sns.lineplot(y='max_proc_time', x='xmlflow_status', data=df4, color="b")
##### Q6

Write code to track the path of a contract in the workflow.


df5 = df_StpFcEntries[['status_taken', 'fc_id', 'xmlflow_status', 'fc_cfamily', 'fc_cgroup', 'fc_ctype']]
df5 = df5[df5['status_taken'].str.contains('Y')]
df5 = df5.sort_values('fc_id')
df5 
unique_contracts = df5['fc_id'].unique()

i = 17
# for i in unique_contracts:
selected_rows = df5.loc[df5['fc_id'] == i]
selected_rows = selected_rows.sort_values('xmlflow_status')
selected_rows
family = selected_rows.iloc[0]['fc_cfamily']
group = selected_rows.iloc[0]['fc_cgroup']
print("Contract", i, "|", family, "|", group, ":", )
# for j in selected_rows['xmlflow_status']:
